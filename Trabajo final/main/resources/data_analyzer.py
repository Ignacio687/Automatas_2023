import pathlib, datetime, os, re, multiprocessing, csv, json
from datetime import datetime, timedelta, date
from collections import Counter

class IncorrectFileExtensionError(Exception):
    pass
  
class modeIndexOutOfRangeError(Exception):
    pass
  
class IncorrectFileFormat(Exception):
    pass
 
class DataAnalyzer():
    def __init__(self, filePath: str | pathlib.Path) -> None:
        """Class capable of validating a specific format csv file and 
        returning filtered data.\n
        filePath: Absolute path of the file"""
        self.filePath = filePath
        
    def setFilePath(self, filePath: str) -> None:
        """"Resets the current file path."""
        self.filePath = filePath

    def __str__(self):
        user_data = self.user_data
        self.fecha_inicio = 0
        self.fecha_fin = 0
        final_str = ''
        for key in user_data.keys():
            final_str += f"\n\n{'-'*55} MOSTRANDO DATOS DESDE {self.fecha_inicio} HASTA {self.fecha_fin} {'-'*55}\n"
            final_str += f"\n{key}:"
            final_str += f"\n\tUsername: {user_data[key]['username']} "
            #final_str += f"\n\tDireccion MAC mas usada: {most_connected_mac}"
            #final_str += f"\n\tDireccion MAC mas tiempo conectada: {mac_with_longest_duration}"
            #mac_keys = [i for i in mac_dict.keys()]
            # Dividir la lista en sublistas de 4 elementos
            #sublists = [mac_keys[i:i+4] for i in range(0, len(mac_keys), 4)]
            # Unir cada sublista utilizando tabulaciones
            #formatted_keys = '\n\t\t'.join(['\t'.join(sublist) for sublist in sublists])
            #final_str += f'\n\tTotal Mac adress:\n\t\t{formatted_keys}'
            final_str += f"\n\tConexiones:"
            for i in user_data[key]['conexiones']:
                final_str += f"\n\t\t{i}"
        return final_str

    def validate(self) -> dict[int, str|int]:
        """Method capable of validating the file format and all data within the lines. 
        Returns a dictionary with all the found errors '{line_index:(header, error)}'."""
        file = open(self.filePath, "r")
        headers = file.readline().split(",")
        if os.path.splitext(self.filePath)[1] != ".csv":
            file.close()
            raise IncorrectFileExtensionError("Not a 'csv' type file")
        pool = multiprocessing.Pool()
        fileLines = file.readlines()
        arguments = ((line, index+2, headers) for index, line in enumerate(fileLines))
        errorsList = pool.starmap(self.subprocessValidation, arguments)
        errorsDict = {}
        for errorDict in errorsList:
            if errorDict != {}:
                errorsDict.update(errorDict)
        file.close()
        return errorsDict
      
    def subprocessValidation(self, line, index, headers) -> dict[int, tuple[str, str]]:
        """Method designed to be run by a subprocess generated by the 'validate' method"""
        errorsDict = {}
        line = line.replace(",,", ",").split(",")
        modeList = [0,1,2,3,4,5,6,7,6,7,8,8,8,9,10]
        for column in range(0, len(modeList)):
            validation = self.expValidation(str(line[column]), modeList[column])
            if not validation:
                errorsDict[index] = (str(headers[column]), str(line[column]))
                break
        return errorsDict

    def expValidation(self, expresion: str, mode: int) -> bool:
        """Method designed to evaluates if a given expresion is valid.\n
        mode: specifies the regular expresion used:\n
        00 - ID\n
        01 - ID_Sesion\n
        02 - ID_Conexión_unico\n
        03 - Usuario\n
        04 - IP_NAS_AP\n
        05 - Tipo__conexión\n
        06 - Inicio_de_Conexión_Dia/Fin_de_Conexión_Dia\n
        07 - Inicio_de_Conexión_Hora/Fin_de_Conexión_Hora\n
        08 - Session_Time/Input_Octects/Output_Octects\n
        09 - MAC_AP\n
        10 - MAC_Cliente\n"""
        regExpList = [
            r"[0-9]+",
            r"[0-9A-F]{1,8}-?[0-9A-F]{1,8}",
            r"[0-9a-f]{8,16}",
            r"[\w\.-]+",
            r"((2([0-4][0-9]|5[0-5])|[0-1]?[0-9]?[0-9])\.){3}(2([0-4][0-9]|5[0-5])|[0-1]?[0-9]?[0-9])",
            r"Wireless-802.11",
            r"(\d{4})(-)(0?[1-9]|1[012])\2(0?[1-9]|[12][0-9]|3[01])",
            r"([01][0-9]|2[0-4]):([0-5][0-9]|60):([0-5][0-9]|60)",
            r"([1-9][0-9]*)|0",
            r"([0-9A-F]{2}-){5}[0-9A-F]{2}:HCDD",
            r"([0-9A-F]{2}-){5}[0-9A-F]{2}"
        ]
        if mode not in range(0,13):
            raise modeIndexOutOfRangeError(f"{mode} is not a mode option")
        regExp = re.compile(regExpList[mode])
        if regExp.fullmatch(expresion):
            return True
        else: return False

    def generateFile(self, path: pathlib.Path | None = None, lines: tuple | None = None) -> str:
        """Method designed to copy the original file, with or without removing lines, 
        into a new directory. Returns the new file absolute path.\n
        path: Absolute directory path where the new file will be.\n
        lines: Indexes of lines willing to remove."""
        if path == None:
            path = pathlib.Path.cwd().joinpath("main", "data")
        fileName = pathlib.Path(self.filePath).name.replace(".csv", "")
        path = path.joinpath(f"{fileName}_filtered.csv")
        with open(self.filePath, "r") as file:
            fileLines = file.readlines()
        if lines != None:
            linesToRemove = list(lines)
            linesToRemove.sort(reverse=True)
            for line in linesToRemove:
                if line-1 in range(1, len(fileLines)):
                    fileLines.pop(line-1)
        with open(path, "w") as file:
            file.writelines([line.replace(',,',',') for line in fileLines if ',,' in line])
            file.flush()
        self.filePath = path.__str__()
        return path.__str__()

    def filterUsers(self, 
                    startDate = '', 
                    endDate = '',
                    filter: bool = True, 
                    ):
        """Method designed to filter the users that have accessed the system on Non-working days. 
        Returns a dictionary {user_name: [total_session_time, most_used_MAC_NWD, most_used_MAC_WD, 
            , total_output_octects]}  *NWD = Non-working days * WD = Working days\n
        filter: if set to False method returns complete list of users\n
        startDate/endDate: if either of them is set to None, the method will take the most old or 
        new date available respectively."""
        if startDate == '':
            fecha_inicio = date(2000, 1, 1) # Fecha antigua para incluir todos los resultados
        else:
            fecha_inicio = startDate
        if endDate == '':
            fecha_fin = date.today()
        else:
            fecha_fin = endDate
        if fecha_fin < fecha_inicio:
            fecha_fin, fecha_inicio = fecha_inicio, fecha_fin

        def is_weekend(fecha_inicio, fecha_fin):
            """Method designed to validate if a date range is has a weekend or holyday.
            Args:
                fecha_inicio (datetime.date): start date
                fecha_fin (datetime.date): end date
            Returns:
                bool: returns True if there is at least one weekend or holyday within the dates range.
            """
            with open(f"main/data/{fecha_inicio.year}.json") as json_file:
                data = json.load(json_file)
                fecha_actual = fecha_inicio
                while fecha_actual <= fecha_fin:
                    month = fecha_actual.month-1
                    day = fecha_actual.strftime("%d")
                    dia_semana = fecha_actual.weekday()
                    if fecha_actual.year != fecha_inicio.year:
                        return is_weekend(fecha_actual, fecha_fin)
                    if dia_semana in [5, 6] or day in [i for i in data[month].keys()]: 
                        return True
                    fecha_actual += timedelta(days=1)
                return False

        user_data = {}
        with open(self.filePath) as csv_file:
            csv_reader = csv.DictReader(csv_file, delimiter=',')
            for index,row in enumerate(csv_reader):
                try:
                    inicio_conexion = datetime.strptime(row['Inicio_de_Conexión_Dia'], "%Y-%m-%d").date()
                    fin_conexion    = datetime.strptime(row['FIN_de_Conexión_Dia'], "%Y-%m-%d").date()
                    session_time    = row['Session_Time']
                    username        = row['Usuario']
                    mac_cliente     = row['MAC_Cliente']
                    input_octets    = row['Input_Octects']
                    output_octects  = row['Output_Octects']
                except Exception as e:
                    print(f"Error en la linea {index+1}: {row}")
                    print(e.args)
                    input()

                if inicio_conexion <= fecha_fin and fin_conexion >= fecha_inicio and is_weekend(max(inicio_conexion, fecha_inicio), min(fin_conexion, fecha_fin)): 
                    if not user_data.get(username):
                        user_data[username] = {'username': username, 'mac_cliente': {}, 'conexiones': [] } 
                    if not user_data[username]['mac_cliente'].get(mac_cliente):
                        user_data[username]['mac_cliente'][mac_cliente] = [0,0]
                    user_data[username]['mac_cliente'][mac_cliente][0] += int(row['Session_Time'])
                    user_data[username]['mac_cliente'][mac_cliente][1] += 1
                    user_data[username]['conexiones'].append(
                        f"{mac_cliente}: {row['Inicio_de_Conexión_Dia']} -> {row['FIN_de_Conexión_Dia']} => Session time: {row['Session_Time']+' hs':<8} | input_octets: {row['Input_Octects']:<10} | output_octects: {row['Output_Octects']:<10}")
            self.user_data = user_data

        #print_data()

if __name__ == '__main__':
    d = DataAnalyzer('/Users/matiasboldrini/Facu/Automatas_2023/Trabajo final/main/data/test_files/test_mati2.csv')
    # d = DataAnalyzer('/Users/matiasboldrini/Facu/Automatas_2023/Trabajo final/archivo.csv')